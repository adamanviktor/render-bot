import os
import time
import requests
from datetime import datetime
from bs4 import BeautifulSoup
from telegram import Bot
from dotenv import load_dotenv

# –ó–∞–≥—Ä—É–∑–∫–∞ –ø–µ—Ä–µ–º–µ–Ω–Ω—ã—Ö –∏–∑ .env
load_dotenv()
TOKEN = os.getenv("TOKEN")
CHAT_ID = os.getenv("CHAT_ID")
THRESHOLD = 100

bot = Bot(token=TOKEN)
seen_urls = set()
bad_urls = set()

def log(msg):
    print(f"[{datetime.now().strftime('%H:%M:%S')}] {msg}")

# –ü–æ–ª—É—á–µ–Ω–∏–µ –≤—Å–µ—Ö —Å—Ç—Ä–∞–Ω–∏—Ü —Å –¥–∞—Ç–∞–º–∏
def fetch_date_pages():
    try:
        url = "https://www.oddsmath.com/matches/"
        r = requests.get(url, timeout=15)
        if r.status_code != 200:
            log(f"–û—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏ –≥–ª–∞–≤–Ω–æ–π —Å—Ç—Ä–∞–Ω–∏—Ü—ã")
            return []
        soup = BeautifulSoup(r.text, "html.parser")
        date_links = []
        for a in soup.select(".calendar a"):
            href = a.get("href", "")
            if "/matches/" in href:
                full = "https://www.oddsmath.com" + href
                date_links.append(full)
        return list(set(date_links))
    except Exception as e:
        log(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –∑–∞–≥—Ä—É–∑–∫–µ –¥–∞—Ç: {e}")
        return []

# –ü–æ–ª—É—á–µ–Ω–∏–µ –º–∞—Ç—á–µ–π —Å –æ–¥–Ω–æ–π –¥–∞—Ç—ã
def fetch_match_links(date_url):
    try:
        r = requests.get(date_url, timeout=15)
        if r.status_code != 200:
            log(f"–û—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏ {date_url}")
            return []
        soup = BeautifulSoup(r.text, "html.parser")
        links = []
        for a in soup.select(".event-table a"):
            href = a.get("href", "")
            if "/match/" in href:
                full = "https://www.oddsmath.com" + href
                links.append(full)
        return list(set(links))
    except Exception as e:
        log(f"–û—à–∏–±–∫–∞ –≤ –¥–∞—Ç–µ {date_url}: {e}")
        return []

# –ü—Ä–æ–≤–µ—Ä–∫–∞ –æ–¥–Ω–æ–≥–æ –º–∞—Ç—á–∞
def check_match(url):
    if url in seen_urls or url in bad_urls:
        return
    seen_urls.add(url)
    try:
        r = requests.get(url, timeout=10)
        if r.status_code != 200:
            return
        soup = BeautifulSoup(r.text, "html.parser")
        bet = soup.select_one("div.back div.value")
        if not bet:
            bad_urls.add(url)
            return
        value = bet.text.replace("‚Ç¨", "").replace(",", "").strip()
        if value.isdigit() and int(value) >= THRESHOLD:
            msg = f"üí∞ BACK: {value} ‚Ç¨\n{url}"
            bot.send_message(chat_id=CHAT_ID, text=msg)
            log(f"–û—Ç–ø—Ä–∞–≤–ª–µ–Ω–æ: {msg}")
    except Exception as e:
        log(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –ø—Ä–æ–≤–µ—Ä–∫–µ {url}: {e}")

# –û—Å–Ω–æ–≤–Ω–æ–π —Ü–∏–∫–ª
if __name__ == "__main__":
    while True:
        date_pages = fetch_date_pages()
        log(f"–ù–∞–π–¥–µ–Ω–æ –¥–∞—Ç: {len(date_pages)}")
        for date_url in date_pages:
            matches = fetch_match_links(date_url)
            log(f"–î–∞—Ç–∞: {date_url} ‚Äî –º–∞—Ç—á–µ–π: {len(matches)}")
            for url in matches:
                check_match(url)
                time.sleep(1)
        time.sleep(1800)
